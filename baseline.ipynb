{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch import autocast\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8182bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliy Functions.\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "# Ensure that we get deterministic results.\n",
    "SEED=1\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529ad22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorBoard\n",
    "writer = SummaryWriter(log_dir=\"/data/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [],
   "source": [
    "# Check that we have a CUDA enabled device\n",
    "if torch.cuda.device_count():\n",
    "    GPU = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26df4464",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "STD_RGB = [0.229, 0.224, 0.225]\n",
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f932ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and val dataset. \n",
    "TRAINDIR = \"/data/train\" # ImageNet train.\n",
    "VALDIR = \"/data/val\" # ImageNet val.\n",
    "BATCH_SIZE = 1 # Autobatch\n",
    "TRAIN_WORKERS = 6\n",
    "VAL_WORKERS = 2\n",
    "\n",
    "# Scale to ImageNet mean and STD since we will be using a model pretrained on ImageNet. \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_RGB, STD_RGB),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(MEAN_RGB, STD_RGB),\n",
    "])\n",
    "\n",
    "# Load training data.\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, num_workers=TRAIN_WORKERS, shuffle=True, pin_memory=True, sampler=None)\n",
    "\n",
    "# Load validation data.\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=BATCH_SIZE, num_workers=VAL_WORKERS, shuffle=True, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d374f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000\n",
    "ARCH = 'resnet18'\n",
    "LR = 1e-4\n",
    "# Load model from PyTorch.\n",
    "model = models.__dict__[ARCH]()\n",
    "inf = model.fc.in_features\n",
    "# Set fully connected layer to train with 1000 classes.\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "# Setup optimizer and loss function. \n",
    "optimizer = torch.optim.Adam(model.parameters(), LR)\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc794f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRINT_FREQ = 1000\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e65743f",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "# Define train step.\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    # Keep progress of metrics.\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # Measure data loading time.\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        # Move data to GPU if CUDA device is available.\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "            \n",
    "        # Use automatic mixed precision (AMP) to increase training speed.\n",
    "        with autocast(\"cuda\"):\n",
    "            # Compute output.\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # Measure accuracy and record loss.\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        # Write tensorboard logs.\n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step=global_step)\n",
    "        writer.add_scalar(\"Acc1/train\", top1.avg, global_step=global_step)\n",
    "        writer.add_scalar(\"Acc5/train\", top5.avg, global_step=global_step)\n",
    "        global_step += 1\n",
    "\n",
    "        # Compute gradient.\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # Measure elapsed time.\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "# Define validation step.\n",
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    # Keep progress of metrics.\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # Switch to evaluate mode.\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            \n",
    "            # Move data to GPU if CUDA device is available.\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # Compute output.\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Measure accuracy and record loss.\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "            \n",
    "\n",
    "            # Measure elapsed time.\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "     # Write tensorboard logs.\n",
    "    writer.add_scalar(\"Loss/val\", loss, global_step=global_step)\n",
    "    writer.add_scalar(\"Acc1/val\", top1.avg, global_step=global_step)\n",
    "    writer.add_scalar(\"Acc5/val\", top5.avg, global_step=global_step)\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][      0/1281167]\tTime  0.812 ( 0.812)\tData  0.229 ( 0.229)\tLoss 6.7422e+00 (6.7422e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][   1000/1281167]\tTime  0.015 ( 0.016)\tData  0.000 ( 0.000)\tLoss 9.0234e+00 (7.8044e+00)\tAcc@1   0.00 (  0.30)\tAcc@5   0.00 (  0.80)\n",
      "Epoch: [0][   2000/1281167]\tTime  0.017 ( 0.016)\tData  0.000 ( 0.000)\tLoss 7.8203e+00 (7.8293e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   0.00 (  0.60)\n",
      "Epoch: [0][   3000/1281167]\tTime  0.015 ( 0.016)\tData  0.000 ( 0.000)\tLoss 6.9492e+00 (7.7673e+00)\tAcc@1   0.00 (  0.13)\tAcc@5   0.00 (  0.60)\n",
      "Epoch: [0][   4000/1281167]\tTime  0.015 ( 0.016)\tData  0.000 ( 0.000)\tLoss 7.6250e+00 (7.6856e+00)\tAcc@1   0.00 (  0.12)\tAcc@5   0.00 (  0.60)\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for epoch in range(1):\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    validate(val_loader, model, criterion)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(f\"Time to Train and 1 Epoch: {end - start}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
